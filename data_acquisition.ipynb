{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import wget\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_cwru_data(dir='.'):\n",
    "    \"\"\"\n",
    "    Download CWRU Bearing dataset\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    dir: str\n",
    "        Directory where the dataset should be stored\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    healthy_assets_url = [\n",
    "        \"http://csegroups.case.edu/sites/default/files/bearingdatacenter/files/Datafiles/97.mat\",\n",
    "        \"http://csegroups.case.edu/sites/default/files/bearingdatacenter/files/Datafiles/98.mat\",\n",
    "        \"http://csegroups.case.edu/sites/default/files/bearingdatacenter/files/Datafiles/99.mat\",\n",
    "        \"http://csegroups.case.edu/sites/default/files/bearingdatacenter/files/Datafiles/100.mat\"\n",
    "    ]\n",
    "    \n",
    "    for url in healthy_assets_url:\n",
    "        if not os.path.isfile('./data_healthy/' + os.path.basename(url)):\n",
    "            wget.download(url=url, out=os.path.realpath('data_healthy/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_cwru_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_folder(folder):\n",
    "    \"\"\"\n",
    "    Separate data from .mat files and convert into arrays.\n",
    "    \n",
    "     'X097_DE_time': array([[ 0.05319692],\n",
    "        [ 0.08866154],\n",
    "        [ 0.09971815],\n",
    "        ...,\n",
    "        [-0.03463015],\n",
    "        [ 0.01668923],\n",
    "        [ 0.04693846]]),\n",
    " 'X097_FE_time': array([[0.14566727],                 (We aim to convert this)\n",
    "        [0.09779636],\n",
    "        [0.05485636],\n",
    "        ...,\n",
    "        [0.14053091],\n",
    "        [0.09553636],\n",
    "        [0.09019455]]),\n",
    " 'X097RPM': array([[1796]], dtype=uint16)}\n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    folder: str\n",
    "        Path of directory where data is stored\n",
    "    \n",
    "    \"\"\"\n",
    "    data = 'dummy'\n",
    "    skip = False\n",
    "    \n",
    "    for file in os.listdir(folder):\n",
    "        file_id = file[:-4]\n",
    "        matlab_file_dict = sio.loadmat(folder+file)\n",
    "        del data\n",
    "        \n",
    "        for key, value in matlab_file_dict.items():\n",
    "            if 'DE_time' in key or 'FE_time' in key:\n",
    "                a = np.array(matlab_file_dict[key])\n",
    "                \n",
    "                try:\n",
    "                    data\n",
    "                except NameError:\n",
    "                    data = a\n",
    "                else:\n",
    "                    if (data.shape[0] != a.shape[0]):\n",
    "                        print('skipping ' + file_id)\n",
    "                        skip = True\n",
    "                        continue\n",
    "                    data = np.hstack((data,a))\n",
    "        \"\"\"\n",
    "        When data has lots of missing entries, filling in data to maintain quality\n",
    "        \n",
    "        \"\"\"\n",
    "        if skip:\n",
    "            skip = False\n",
    "            continue\n",
    "        id = np.repeat(file_id, data.shape[0])\n",
    "        id.shape = (id.shape[0],1)\n",
    "        data = np.hstack((id,data))\n",
    "        if data.shape[1] == 2:\n",
    "            zeroes = np.repeat(float(0),data.shape[0])\n",
    "            zeroes.shape = (data.shape[0],1)\n",
    "            data = np.hstack((data,zeroes))\n",
    "        try:\n",
    "            result\n",
    "        except NameError:\n",
    "            result = data\n",
    "        else:\n",
    "            result = np.vstack((result,data))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping 99\n",
      "skipping 99\n"
     ]
    }
   ],
   "source": [
    "result_healthy = read_folder('./data_healthy/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.DataFrame(result_healthy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.014603076923076923</td>\n",
       "      <td>0.19292181818181817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>0.05444861538461539</td>\n",
       "      <td>0.16436363636363635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>0.10764553846153846</td>\n",
       "      <td>0.09081090909090908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>0.13372246153846154</td>\n",
       "      <td>0.08649636363636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>0.11265230769230769</td>\n",
       "      <td>0.09923454545454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213479</th>\n",
       "      <td>98</td>\n",
       "      <td>-0.04318338461538461</td>\n",
       "      <td>-0.05362363636363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213480</th>\n",
       "      <td>98</td>\n",
       "      <td>-0.06738276923076922</td>\n",
       "      <td>-0.055883636363636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213481</th>\n",
       "      <td>98</td>\n",
       "      <td>-0.09909230769230769</td>\n",
       "      <td>-0.007601818181818181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213482</th>\n",
       "      <td>98</td>\n",
       "      <td>-0.10827138461538462</td>\n",
       "      <td>0.0402690909090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213483</th>\n",
       "      <td>98</td>\n",
       "      <td>-0.07092923076923077</td>\n",
       "      <td>0.06101999999999999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1213484 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                     1                      2\n",
       "0        100  0.014603076923076923    0.19292181818181817\n",
       "1        100   0.05444861538461539    0.16436363636363635\n",
       "2        100   0.10764553846153846    0.09081090909090908\n",
       "3        100   0.13372246153846154    0.08649636363636364\n",
       "4        100   0.11265230769230769    0.09923454545454545\n",
       "...      ...                   ...                    ...\n",
       "1213479   98  -0.04318338461538461   -0.05362363636363636\n",
       "1213480   98  -0.06738276923076922  -0.055883636363636364\n",
       "1213481   98  -0.09909230769230769  -0.007601818181818181\n",
       "1213482   98  -0.10827138461538462     0.0402690909090909\n",
       "1213483   98  -0.07092923076923077    0.06101999999999999\n",
       "\n",
       "[1213484 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.to_csv('result_healthy_pandas.csv', header=False, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Moving on to downloading faulty data from 3 different links;\n",
    "    - 12k-drive-end-bearing-fault-data\n",
    "    - 48k-drive-end-bearing-fault-data\n",
    "    - 12k-fan-end-bearing-fault-data\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "req1 = requests.get(\"https://csegroups.case.edu/bearingdatacenter/pages/12k-drive-end-bearing-fault-data\")\n",
    "soup1 = BeautifulSoup(req1.text, \"lxml\")\n",
    "\n",
    "pages1 = soup1.findAll('a', href=re.compile('.*Datafiles?.*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "req2 = requests.get(\"https://csegroups.case.edu/bearingdatacenter/pages/48k-drive-end-bearing-fault-data\")\n",
    "soup2 = BeautifulSoup(req2.text, \"lxml\")\n",
    "\n",
    "pages2 = soup2.findAll('a', href=re.compile('.*Datafiles?.*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "req3 = requests.get(\"https://csegroups.case.edu/bearingdatacenter/pages/12k-fan-end-bearing-fault-data\")\n",
    "soup3 = BeautifulSoup(req3.text, \"lxml\")\n",
    "\n",
    "pages3 = soup3.findAll('a', href=re.compile('.*Datafiles?.*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_file(url):\n",
    "    \"\"\"\n",
    "    Scraping CRWU website for faulty bearing dataset\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    url: str\n",
    "        String from <pages> list where the faulty data is online\n",
    "    \n",
    "    \"\"\"\n",
    "    \"\"\"path = url['href']\n",
    "    r = requests.get(url, stream=True)\n",
    "    if r.status_code == 200:\n",
    "        with open(path, 'wb') as f:\n",
    "            for chunk in r:\n",
    "                f.write(chunk)\n",
    "    \"\"\"\n",
    "    path=[]\n",
    "    for link in url:\n",
    "        if link.has_attr('href'):\n",
    "            path.append(link['href'])\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "faulty_url1 = scrape_file(pages1)\n",
    "\n",
    "faulty_url2 = scrape_file(pages2)\n",
    "\n",
    "faulty_url3 = scrape_file(pages3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "faulty_url = faulty_url1 + faulty_url2 + faulty_url3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_faulty(dir='.'):\n",
    "    \"\"\"\n",
    "    Download faulty bearing dataset\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    dir: str\n",
    "        Directory where the dataset should be stored\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    for url in faulty_url:\n",
    "        if not os.path.isfile('./data_faulty/' + os.path.basename(url)):\n",
    "            wget.download(url=url, out=os.path.realpath('data_faulty/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [..........................................................................] 7779920 / 7779920"
     ]
    }
   ],
   "source": [
    "download_faulty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_faulty = read_folder('./data_faulty/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpdf = pd.DataFrame(result_faulty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpdf.tocsv('result_faulty_pandas.csv', header=False, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Additionally cleaning up artifacts for memory limited machines\n",
    "    and cleaning up directories for files\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "del result_healthy\n",
    "del result_faulty\n",
    "del pdf\n",
    "del fpdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shutil.move('/Users/krishnateja.kuppa/Documents/Python Scripts/result_healthy_pandas.csv', '/Users/krishnateja.kuppa/Documents/Python Scripts/data_healthy/result_healthy_pandas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shutil.move('/Users/krishnateja.kuppa/Documents/Python Scripts/result_faulty_pandas.csv', '/Users/krishnateja.kuppa/Documents/Python Scripts/data_healthy/result_faulty_pandas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
